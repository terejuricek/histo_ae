{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2348912b",
   "metadata": {},
   "source": [
    "## No use of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA - no labels\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),             # convert to [C,H,W] tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # scale to [-1,1]\n",
    "])\n",
    "\n",
    "PATCHES_PATH = \"/Volumes/tereju_disk/RECETOX/autoencoder/coad/kather01/01_TUMOR\"\n",
    "\n",
    "# Custom Dataset for WSI patches\n",
    "class WSIPatchDataset(Dataset):\n",
    "    def __init__(self, patches_dir, transform=None):\n",
    "        self.patches_dir = patches_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Find all .tif files in the directory\n",
    "        self.patch_files = glob.glob(os.path.join(patches_dir, \"*.tif\"))\n",
    "        print(f\"Found {len(self.patch_files)} .tif files\")\n",
    "        \n",
    "        if len(self.patch_files) == 0:\n",
    "            # Try other common extensions\n",
    "            for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.tiff\"]:\n",
    "                self.patch_files.extend(glob.glob(os.path.join(patches_dir, ext)))\n",
    "        \n",
    "        print(f\"Total patches found: {len(self.patch_files)}\")\n",
    "        \n",
    "        if len(self.patch_files) == 0:\n",
    "            raise FileNotFoundError(f\"No image files found in {patches_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patch_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patch_path = self.patch_files[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(patch_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, 0  # Return 0 as dummy label for autoencoder\n",
    "\n",
    "# Create dataset and dataloader\n",
    "try:\n",
    "    dataset = WSIPatchDataset(PATCHES_PATH, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    print(f\"Dataset created successfully with {len(dataset)} patches\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating dataset: {e}\")\n",
    "    print(f\"Please check if the path exists: {PATCHES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder Architecture - NO Class\n",
    "\n",
    "# Encoder\n",
    "encoder = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),                               # [B, 32, 75, 75]\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),                              # [B, 64, 38, 38]\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),                             # [B, 128, 19, 19]\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# Decoder\n",
    "decoder = nn.Sequential(\n",
    "    nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # [B, 64, 38, 38]\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),   # [B, 32, 75, 75]\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),    # [B, 3, 150, 150]\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# MODEL: apply encoder then decoder\n",
    "def autoencoder(x):\n",
    "    z = encoder(x)\n",
    "    out = decoder(z)\n",
    "    return out\n",
    "\n",
    "# Example: run a forward pass\n",
    "x = torch.randn(1, 3, 150, 150)   # fake input\n",
    "y = autoencoder(x)\n",
    "print(y.shape)  # should be [1,3,150,150]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
